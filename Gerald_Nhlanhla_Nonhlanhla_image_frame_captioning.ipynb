{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "YPDtCvujF74c"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from transformers import pipeline\n",
        "from PIL import Image\n",
        "\n",
        "# Load the video\n",
        "video = \"/content/video.mp4\"\n",
        "cap = cv2.VideoCapture(video)\n",
        "\n",
        "skip_frames = 100\n",
        "\n",
        "# Initialize the image captioning pipeline\n",
        "captioner = pipeline(\"image-to-text\", model=\"Salesforce/blip-image-captioning-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "am1zEqxqmnT8",
        "outputId": "2fdd4bee-ec47-418d-b864-b1128cd8e103"
      },
      "outputs": [],
      "source": [
        "# Extract frames and generate captions\n",
        "frame_captions_dict = {}\n",
        "captions = []\n",
        "frame_count = 0\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    print(\"Processing frame...\", flush=True)\n",
        "    if frame_count % skip_frames == 0:\n",
        "      try:\n",
        "        # Processing the frame\n",
        "        image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "        print(\"Image converted to PIL\")\n",
        "\n",
        "        # Generating caption\n",
        "        caption = captioner(image, max_new_tokens=50)[0]['generated_text']\n",
        "        print(\"Caption generated\")\n",
        "\n",
        "        # Storing the caption in the empty list initiated at the begining\n",
        "        captions.append((frame, caption))\n",
        "        print(caption)\n",
        "\n",
        "        # Storing the captions in the dictionary\n",
        "        frame_captions_dict[frame_count] = caption\n",
        "        print(\"Caption stored in the dictionary\")\n",
        "      except Exception as e:\n",
        "          print(f\"Error processing frame: {e}\")\n",
        "          continue\n",
        "    frame_count += 1\n",
        "    print(f\"Processing frame {frame_count}...\", flush=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uUlzjirMm29L"
      },
      "outputs": [],
      "source": [
        "# Release the video capture\n",
        "cap.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXV3Qb6Wm_oj",
        "outputId": "ac1223a6-a79b-4d1f-aab9-acf83b9c45d1"
      },
      "outputs": [],
      "source": [
        "# Printing the generated captions\n",
        "for frame_count, cation in frame_captions_dict.items():\n",
        "    print(f\" Frame {frame_count} : Caption {caption}\", flush=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
